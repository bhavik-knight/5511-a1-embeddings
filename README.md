# MCDA5511 - Assignment1 - Sentence Embeddings

This project visualizes the similarity between classmates based on their stated interests using high-dimensional sentence embeddings and UMAP dimensionality reduction.

The application uses the `all-MiniLM-L6-v2` model to generate 384-dimensional embeddings, which are then projected into 2D for interactive or static visualization.

## Generated Visualization

![Classmates similarity visualization](output/visualization.png)

## Project Architecture & Refactoring

The project has been refactored into a modular, professional Python structure to ensure maintainability and testability.

### Key Components:
- **`src/config.py`**: Centralized configuration for all file paths, model names, and visualization settings.
- **`src/utils.py`**: A shared utility hub containing standardized mathematical functions (Cosine Similarity, Spearman Rank Correlation) and common I/O operations for embeddings.
- **`src/data_loader.py`**: Handles CSV parsing and data extraction.
- **`src/embedding_manager.py`**: Manages the loading of SentenceTransformer models and the generation/caching of embeddings.
- **`src/visualizer.py`**: Encapsulates the UMAP reduction and Matplotlib plotting logic.

---

## Directory Structure

```text
.
├── data
│   └── classmates.csv          # Input data
├── output
│   ├── embeddings.json         # Generated embeddings (cached)
│   ├── optimization_history.png # UMAP HPO results
│   ├── umap_hpo_results.csv    # Full HPO trial logs
│   ├── visualization.png       # Final 2D plot
│   └── visualization_seed_*.png # Stability test plots
├── src
│   ├── __init__.py
│   ├── config.py               # Central config
│   ├── data_comparison.py      # Sensitivity analysis script
│   ├── data_loader.py          # Data ingestion
│   ├── embedding_manager.py    # Embedding orchestration
│   ├── main.py                 # Primary entry point
│   ├── model_comparison.py     # Cross-model ranking analysis
│   ├── umap_hpo.py             # Bayesian hyperparameter tuning
│   ├── utils.py                # Shared math/IO utilities
│   └── visualizer.py           # UMAP/Plotting engine
├── pyproject.toml              # Dependencies (uv)
└── uv.lock                     # Lockfile
```

## How to Run

This project uses `uv` for dependency management.

### 1. Initial Setup
```bash
uv sync
```

### 2. Generate Main Visualization
This runs the full pipeline: load data -> generate embeddings -> save -> plot.
```bash
uv run python src/main.py
```

### 3. Run Model Comparison Analysis
Compares rankings between `all-MiniLM-L6-v2` and `all-mpnet-base-v2`.
```bash
uv run python src/model_comparison.py
```

### 4. Run Data Sensitivity Analysis
Measures the impact of minor (synonym) vs. major (antonym) text changes on embedding vectors.
```bash
uv run python src/data_comparison.py
```

### 5. Run UMAP Hyperparameter Optimization (HPO)
Uses Optuna to find the best UMAP parameters for preserving global structure.
```bash
uv run python src/umap_hpo.py
```

---

## What Are Embeddings?
### By: Miguel Angel Palafox Gomez

Mathematical models need numbers to perform calculations, not letters or words. Because of this, words and sentences must be transformed into numerical representations so that algorithms can process them and perform tasks such as clustering, classification, or similarity detection. 

These numerical representations are called embeddings. However, these numbers cannot simply be random. They must preserve meaning so that the relationships between words and sentences are reflected accurately. Embeddings are generated by deep learning models that learn patterns from large amounts of text and assign numbers in a meaningful way. These models learn which words and sentences tend to appear in similar contexts and use that information to create representations that capture meaning.  

A well-known example of word embeddings illustrates how meaning can be preserved through numerical relationships. If we take the embedding for the word “king”, subtract the embedding for “male”, and then add the embedding for “female”, the result is numerically close to the embedding for “queen”. This shows that embeddings capture relationships such as gender and roles, not just the spelling of words. In this way, embeddings allow mathematical models to reason about language in a way that reflects real-world meaning and associations.  

Sentence embeddings work in a similar way but operate on entire sentences rather than individual words. Instead of representing a single word, the model analyzes the overall meaning of a sentence and assigns a numerical representation that reflects its themes and context. For example, a student who writes “I enjoy gaming and playing cricket and volleyball” may be placed near someone who mentions sports or other recreational activities, even if they use different wording. Likewise, someone who says “I like to watch movies, reading detective novels and listening music” might appear close to another student who enjoys reading books, hiking, and watching documentaries because both descriptions reflect leisure activities such as reading and entertainment. Even though the exact words differ, the underlying interests are similar, and embeddings capture that similarity. By converting language into meaningful numerical form, embeddings make it possible for algorithms to compare, group, and visualize text based on meaning rather than exact wording. This allows models to identify patterns and relationships across large collections of text. 

The following figure illustrates a simple three-dimensional example of embeddings. In this illustrative representation, one dimension can be interpreted as a royalty-related attribute, another as a gender-related attribute, and the third as an additional contextual dimension. The embeddings (coordinates) shown are illustrative and were created for explanatory purposes to help visualize how embeddings can represent semantic relationships and analogies, such as how the relationship between king and queen reflects the relationship between male and female.

![Example of embeddings](output/embeddings_example_plot.png)

---

## Data Analysis Experiments: Sensitivity Analysis
### By: Bhavik Kantilal Bhagat

The sensitivity analysis measures how much the embedding vector changes when we modify the input text. High similarity (≈1.0) indicates the model is robust to the change; lower similarity indicates the model detected a significant semantic shift.

| Name | Major Change? | Original Description | New Description | Similarity |
| --- | --- | --- | --- | --- |
| Greg Kirczenow | No | "Swim, bike, run" | "swimming, cycling, running" | 0.8734 |
| Mohammad Pakdoust | Yes | "...passionate about outdoor activities..." | "...prefer to stay indoors..." | 0.5617 |
| Bhavik Bhagat | No | "Chess, Maths and Music." | "I enjoy playing chess, solving math puzzles..." | 0.7275 |

### Key Insights:
1. **Minor Changes (Synonyms)** results stay in the **0.70-0.90** range. The model recognizes the context remains identical despite phrasing differences.
2. **Major Changes (Antonyms)** drop the similarity significantly to the **0.40-0.70** range, showing the transformer's sensitivity to semantic intent.

---

## Embedding Sensitivity Tests: Model Comparison
### By: Nikola Kriznar
To test how sensitive results are to the model choice, we compared `all-MiniLM-L6-v2` with the 3x larger `all-mpnet-base-v2`.

**Latest Results (for Nikola Kriznar):**
* **Spearman's Rank Correlation:** 0.5343 (Moderate agreement)

While the overall relationship density is moderately preserved, the models prioritize different semantic features:
- **MiniLM** (Smaller) matched me with classmates explicitly listing "Music" as a primary keyword.
- **MPNet** (Larger) identified more subtle semantic links, such as the relationship between "competitive gaming" and specific video game interests.

---

## UMAP Hyperparameter Optimization
### By: Sridhar Vadla

To ensure the 2D visualization accurately reflects the 384-dimensional relationships, we implemented **Bayesian Optimization** via **Optuna**.

The optimization objective maximizes the **Spearman Correlation** between high-dimensional cosine similarities and low-dimensional Euclidean distances.

### Optimized Parameters:
| Best Trial | Metric | n_neighbors | min_dist | Spearman Score |
| :--- | :--- | :--- | :--- | :--- |
| **Trial 96** | **manhattan** | **8** | **0.051** | **0.5641** |

#### Search Convergence & Stability:
![Optimization History](output/optimization_history.png)

**Stability Insight:** Using the optimized parameters (Manhattan distance, 8 neighbors), the visualization remains visually stable across different random seeds, confirming that the clusters are meaningful and not artifacts of dimensionality reduction noise.
